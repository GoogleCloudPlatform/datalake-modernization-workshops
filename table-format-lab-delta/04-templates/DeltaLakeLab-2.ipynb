{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4529a790-8425-4600-841a-4b094b82eaa8",
   "metadata": {},
   "source": [
    "# Delta Lake Lab \n",
    "## Unit 2: Create a Delta Lake table\n",
    "In the previous unit -\n",
    "1. We read parquet data in the datalake\n",
    "2. Cleansed it, subset it and persisted it as parquet to the datalake parquet-consumable directory\n",
    "3. We crated a database called loan_db and defined an external table on the data in parquet-consumable\n",
    "\n",
    "In this unit you will learn to -\n",
    "1. Create a base table in Delta off of the Parquet table in the prior notebook.\n",
    "2. Create a partitioned Delta table off of the Parquet table in the prior notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c4fd-d465-4f52-8e56-3775bf499abc",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321bce9-178c-4065-8187-0a5728c1a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import month, date_format\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295a74-ed1d-4b5d-831a-1b5dcf73c36f",
   "metadata": {},
   "source": [
    "### 2. Create a Spark session powered by Cloud Dataproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383d5ab-a0b9-45ab-a232-34d88f2a0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Loan Analysis').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd13e6-f3f5-4f2c-b4fc-d7e2660c6206",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596e31b-749a-4702-8879-6f05f9ff0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_output = !gcloud config list --format \"value(core.project)\" 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "print(\"PROJECT_ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c6743-a058-462b-851a-f34323f36243",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_output = !gcloud projects describe $PROJECT_ID | grep name | cut -d':' -f2 | xargs\n",
    "PROJECT_NAME = project_name_output[0]\n",
    "print(\"PROJECT_NAME: \", PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f75330",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NAME = \"YOUR_ACCOUNT_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61929dc6-a083-433c-8a13-3d39d9c4a4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_number_output = !gcloud projects describe $PROJECT_ID | grep projectNumber | cut -d':' -f2 | xargs\n",
    "PROJECT_NUMBER = project_number_output[0]\n",
    "print(\"PROJECT_NUMBER: \", PROJECT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b79fd2-5243-41a4-ae87-e7f9dd87cf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_LAKE_ROOT_PATH= f\"gs://dll-data-bucket-{PROJECT_NUMBER}-{ACCOUNT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7c08d-a9e2-4992-8de4-15c6b8039f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_LAKE_DIR_ROOT = f\"{DATA_LAKE_ROOT_PATH}/delta-consumable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af85d5-27a5-4307-8778-d7c3594e5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delta dataset from the Parquet table\n",
    "spark.sql(\"SELECT addr_state,count(*) as count FROM \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_parquet group by addr_state\").write.mode(\"overwrite\").format(\"delta\").save(f\"{DELTA_LAKE_DIR_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9b9ce-0e71-4e9e-b8dd-8377c0ae7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define external delta table definition\n",
    "spark.sql(\"DROP TABLE IF EXISTS \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_delta;\").show(truncate=False)\n",
    "spark.sql(f\"CREATE TABLE YOUR_ACCOUNT_NAME_loan_db.loans_by_state_delta USING delta LOCATION \\\"{DELTA_LAKE_DIR_ROOT}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630f3b9-1333-450b-a6fc-7c6c4d2a7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables from \"+ ACCOUNT_NAME +\"_loan_db;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce6b8c-b366-457c-a870-68f336d95f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_delta limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e1bc2-d0e9-4f7b-b4b0-25082cbe7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa4248-2cd4-415c-a690-5b4f627d557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_delta\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b2095-91c7-41d5-9fc0-092c3511d0c4",
   "metadata": {},
   "source": [
    "### 5. Create a partitioned Delta Lake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6e4ba-742b-44ce-b58a-590dcf42eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_LAKE_DIR_ROOT = f\"{DATA_LAKE_ROOT_PATH}/delta-sample-partitioned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8230a-609a-4ae3-a990-17498ae6144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delta dataset from the Parquet table\n",
    "spark.sql(\"SELECT addr_state,count(*) as count FROM \"+ ACCOUNT_NAME +\"_loan_db.loans_by_state_parquet group by addr_state\").write.mode(\"overwrite\").partitionBy(\"addr_state\").format(\"delta\").save(f\"{DELTA_LAKE_DIR_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0468c88-4f56-48af-9165-d4f1bbcbbda3",
   "metadata": {},
   "source": [
    "### 6. A quick peek at the data lake layout\n",
    "Compare this to the last cell of the prior notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417104e-973f-422a-9bf1-e484a65b9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -r $DATA_LAKE_ROOT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2148014-f271-4c7b-86ec-f925ede3a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -r $DATA_LAKE_ROOT_PATH/delta-consumable/part* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4df240-5ff1-433b-92ed-cf311dbef082",
   "metadata": {},
   "source": [
    "### THIS CONCLUDES THIS UNIT. PROCEED TO THE NEXT NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "serverless_spark": "{\"name\":\"projects/delta-lake-lab/locations/us-central1/sessions/delta-lake-lab-10060\",\"uuid\":\"cc6b1af7-fba9-41fd-b379-13891e4f5d78\",\"createTime\":\"2022-11-01T20:50:13.532739Z\",\"jupyterSession\":{},\"spark\":{},\"runtimeInfo\":{\"endpoints\":{\"Spark History Server\":\"https://smmei2wdurb7nptroshcbbgeda-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/?eventLogDirFilter=cc6b1af7-fba9-41fd-b379-13891e4f5d78\"}},\"state\":\"ACTIVE\",\"stateTime\":\"2022-11-01T20:51:39.593533Z\",\"creator\":\"admin@akhanolkar.altostrat.com\",\"runtimeConfig\":{\"version\":\"2.0\",\"properties\":{\"spark:spark.jars.packages\":\"io.delta:delta-core_2.13:2.1.0\",\"spark:spark.sql.catalog.spark_catalog\":\"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\"spark:spark.sql.extensions\":\"io.delta.sql.DeltaSparkSessionExtension\",\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.dynamicAllocation.executorAllocationRatio\":\"0.3\",\"spark:spark.eventLog.dir\":\"gs://dll-sphs-bucket-885979867746/cc6b1af7-fba9-41fd-b379-13891e4f5d78/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"serviceAccount\":\"dll-lab-sa@delta-lake-lab.iam.gserviceaccount.com\",\"subnetworkUri\":\"spark-snet\",\"idleTtl\":\"14400s\"},\"peripheralsConfig\":{\"metastoreService\":\"projects/delta-lake-lab/locations/us-central1/services/dll-hms-885979867746\",\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/delta-lake-lab/regions/us-central1/clusters/dll-sphs-885979867746\"}}},\"stateHistory\":[{\"state\":\"CREATING\",\"stateStartTime\":\"2022-11-01T20:50:13.532739Z\"}]}",
  "serverless_spark_kernel_name": "remote-55063bd6660cfbfe1596a3af-pyspark",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
